{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32c50400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0fd5cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset_Divar_EDA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b120425",
   "metadata": {},
   "source": [
    "# normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09f89958",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = hazm.Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d763b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = list(range(ord(\"۰\"), ord(\"۹\")+1))\n",
    "numbers.extend(list(range(ord(\"0\"), ord(\"9\")+1)))\n",
    "chars = list(range(ord(\"آ\"), ord(\"ی\")+20))\n",
    "chars.extend(list(range(ord(\"A\"), ord(\"z\")+1)))\n",
    "\n",
    "signs = [\",\", \".\", \"?\", \";\", \":\", \"(\", \")\", \"$\", \"%\", \"!\", \"\\'\", \"\\\"\", \"{\", \"}\", \"[\", \"]\", \"&\", \n",
    "           \"،\", \"؛\", \"«\", \"»\", \"؟\", \"!\", \" \", \"‌\",\"?\",\"@\",\"1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "208720f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def check_char(text):\n",
    "    res = \"\"\n",
    "    for t in text:\n",
    "        \n",
    "            if ord(t) in chars or ord(t) in numbers or t in signs:\n",
    "                res += t\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ccc64d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(text):\n",
    "    while (\"\\n\" in text) or (\"\\r\\n\" in text) or (\"\\n\\r\" in text):\n",
    "        text = text.replace(\"\\n\", \" \").replace(\"\\n\\r\", \" \").replace(\"\\r\\n\", \" \").replace(\"\\u200c\",\" \")\n",
    "    text = check_char(text)\n",
    "    text = normalizer.normalize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7621e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = [normalize(d) for d in df['description']]\n",
    "df['title'] = [normalize(d) for d in df['title']]\n",
    "df['sub_title'] = [normalize(d) for d in df['sub_title']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c8aabe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('normalize_divar_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa32d005",
   "metadata": {},
   "source": [
    "# tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "beb74914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_tf_idf(sentence_list):\n",
    "    # Get word frequency for each sentence\n",
    "    tf_dict = []\n",
    "    for sentence in sentence_list:\n",
    "        word_count = Counter(sentence.split())\n",
    "        tf_dict.append({word: count/len(word_count) for word, count in word_count.items()})\n",
    "        \n",
    "    # Calculate IDF\n",
    "    idf_dict = {}\n",
    "    N = len(sentence_list)\n",
    "    for sentence in sentence_list:\n",
    "        for word in set(sentence.split()):\n",
    "            if word not in idf_dict:\n",
    "                count = sum(1 for s in sentence_list if word in s.split())\n",
    "                idf_dict[word] = math.log(N/count)\n",
    "    \n",
    "    # Calculate TF-IDF\n",
    "    tf_idf_dict = []\n",
    "    for tf in tf_dict:\n",
    "        tf_idf = {}\n",
    "        for word, freq in tf.items():\n",
    "            tf_idf[word] = freq * idf_dict.get(word, 0)\n",
    "        tf_idf_dict.append(tf_idf)\n",
    "        \n",
    "    return tf_idf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0100bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_title = []\n",
    "sentences_description = []\n",
    "sentences_sub_title = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    sentences_title.append(df.iat[i,5])\n",
    "    sentences_description.append(df.iat[i,6])\n",
    "    sentences_sub_title.append(df.iat[i,8])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "92097362",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_title = calculate_tf_idf(sentences_title)\n",
    "tf_idf_description = calculate_tf_idf(sentences_description)\n",
    "tf_idf_sub_title = calculate_tf_idf(sentences_sub_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e2178d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=6, column='description_encoding', value=tf_idf_description)\n",
    "df.insert(loc=5, column='title_encoding', value=tf_idf_title)\n",
    "df.insert(loc=10, column='sub_title_encoding', value=tf_idf_sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a145d0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2aa0ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tf_idf_embedding_divar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f4891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff24ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0f8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485be3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
